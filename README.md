# RLearning

Code being developed while studying the book "Reinforcement Learning: An Introduction", by Richard A. Sutton and Andrew G. Barto.

## Chapter 2: Multi-armed Bandits

Some results for the <i>"sample-averaged"</i>, <i>&epsilon;-greedy</i> 10-armed bandit model are presented below:

<p align="center">
    <img src="img/ch2/Figure_2.1.png" width="100%" height="100%"><br>
    <b>Figure 2.1.</b> Rewards for each action in a 10-armed bandit.
</p>

<p align="center">
    <img src="img/ch2/Figure_2.2.png"><br>
    <b>Figure 2.2.</b> Results from 2000 runs of 1000 steps each for varying &epsilon; values.
</p>

<p align="center">
    <img src="img/ch2/Figure_2.3.png"><br>
    <b>Figure 2.3.</b> Results from 2000 runs of 1000 steps each. <a style="color:blue";>Blue:</a> greedy steps with optimistic initial values; <a style="color:red">Red:</a> &epsilon;-greedy steps.
</p>

<p align="center">
    <img src="img/ch2/Figure_2.4.png"><br>
    <b>Figure 2.4.</b> Results from 2000 runs of 1000 steps each. <a style="color:blue";>Blue:</a> upper-confidence bound greedy steps; <a style="color:grey">Grey:</a> &epsilon;-greedy steps.
</p>